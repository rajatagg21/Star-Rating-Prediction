{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-01T19:13:59.806475Z","iopub.execute_input":"2022-03-01T19:13:59.806847Z","iopub.status.idle":"2022-03-01T19:13:59.865749Z","shell.execute_reply.started":"2022-03-01T19:13:59.806757Z","shell.execute_reply":"2022-03-01T19:13:59.865022Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/starratingprediction-part-2/__results__.html\n/kaggle/input/starratingprediction-part-2/__resultx__.html\n/kaggle/input/starratingprediction-part-2/__notebook__.ipynb\n/kaggle/input/starratingprediction-part-2/__output__.json\n/kaggle/input/starratingprediction-part-2/custom.css\n/kaggle/input/starratingprediction-part-2/models/model_uni75.sav\n/kaggle/input/starratingprediction-part-2/models/vectorizer_uni25.sav\n/kaggle/input/starratingprediction-part-2/models/model_tri25.sav\n/kaggle/input/starratingprediction-part-2/models/model_uni50.sav\n/kaggle/input/starratingprediction-part-2/models/vectorizer_uni50.sav\n/kaggle/input/starratingprediction-part-2/models/vectorizer_bi25.sav\n/kaggle/input/starratingprediction-part-2/models/vectorizer_uni75.sav\n/kaggle/input/starratingprediction-part-2/models/vectorizer_tri25.sav\n/kaggle/input/starratingprediction-part-2/models/model_uni25.sav\n/kaggle/input/starratingprediction-part-2/models/model_bi50.sav\n/kaggle/input/starratingprediction-part-2/models/vectorizer_bi50.sav\n/kaggle/input/starratingprediction-part-2/models/model_bi25.sav\n/kaggle/input/starratingprediction-part-2/__results___files/__results___11_0.png\n/kaggle/input/amazon-mobile-phone-reviews-dataset/SRPtest.csv\n/kaggle/input/amazon-mobile-phone-reviews-dataset/SRPtrain.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Star Rating prediction (Part-4)**\n\n**In this notebook, we are going to test Naive Bayes Classifiers trained earlier in <a href=\"https://www.kaggle.com/rajatagg/star-rating-prediction-part-2?scriptVersionId=88922233\">Part-2</a>**\n\n* <a href=\"https://www.kaggle.com/rajatagg/star-rating-prediction-part-1?scriptVersionId=84763077\">Part-1: Data Analysis and text preprocessing</a>\n* <a href=\"https://www.kaggle.com/rajatagg/star-rating-prediction-part-2\">Part-2: Feature vector generation using Multinomial Naive Bayes Classifier</a>\n* <a href=\"https://www.kaggle.com/rajatagg/starratingprediction-part-3/notebook\">Part-3: Training and testing using Random Forest Algorithm</a>","metadata":{}},{"cell_type":"markdown","source":"> **Loading the test dataset**","metadata":{}},{"cell_type":"code","source":"X_test_df = pd.read_csv('/kaggle/input/amazon-mobile-phone-reviews-dataset/SRPtest.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:14:02.357856Z","iopub.execute_input":"2022-03-01T19:14:02.358278Z","iopub.status.idle":"2022-03-01T19:14:03.701141Z","shell.execute_reply.started":"2022-03-01T19:14:02.358248Z","shell.execute_reply":"2022-03-01T19:14:03.700206Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X_test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:14:03.702972Z","iopub.execute_input":"2022-03-01T19:14:03.703331Z","iopub.status.idle":"2022-03-01T19:14:03.723517Z","shell.execute_reply.started":"2022-03-01T19:14:03.703287Z","shell.execute_reply":"2022-03-01T19:14:03.722479Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                             Reviews  Rating\n0  I've been a long time fan of lg's phones and l...       5\n1  Great Phone for the price, very quickly. The c...       5\n2  Bye bye iPhone. After much research and many q...       5\n3                                Allí was ver y fine       5\n4     The ringer volume is poor, It needs beefing up       4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Reviews</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I've been a long time fan of lg's phones and l...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Great Phone for the price, very quickly. The c...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bye bye iPhone. After much research and many q...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Allí was ver y fine</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The ringer volume is poor, It needs beefing up</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#  its a python script containing functions used in preprocessing\nimport functions_for_text_preprocessing as pptext","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:15:29.371444Z","iopub.execute_input":"2022-03-01T19:15:29.371715Z","iopub.status.idle":"2022-03-01T19:15:30.949792Z","shell.execute_reply.started":"2022-03-01T19:15:29.371688Z","shell.execute_reply":"2022-03-01T19:15:30.948816Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"pptext.all_functions()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:15:33.230956Z","iopub.execute_input":"2022-03-01T19:15:33.231277Z","iopub.status.idle":"2022-03-01T19:15:33.237338Z","shell.execute_reply.started":"2022-03-01T19:15:33.231241Z","shell.execute_reply":"2022-03-01T19:15:33.236587Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'This module contain : expandContractions, tokenization, removeStopwords, lemmatizeText, preprocess_review, getWordCount, getReviewLength.\\nReview text is the only input'"},"metadata":{}}]},{"cell_type":"markdown","source":"> **preprocessing the text data**","metadata":{}},{"cell_type":"code","source":"X_test_df['Reviews'] = X_test_df['Reviews'].apply(pptext.preprocess_review)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:15:34.540554Z","iopub.execute_input":"2022-03-01T19:15:34.541156Z","iopub.status.idle":"2022-03-01T19:16:04.268469Z","shell.execute_reply.started":"2022-03-01T19:15:34.541117Z","shell.execute_reply":"2022-03-01T19:16:04.267434Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"> **importing the library to load the saved models**","metadata":{}},{"cell_type":"code","source":"import joblib","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:16:15.265482Z","iopub.execute_input":"2022-03-01T19:16:15.266465Z","iopub.status.idle":"2022-03-01T19:16:15.270101Z","shell.execute_reply.started":"2022-03-01T19:16:15.266404Z","shell.execute_reply":"2022-03-01T19:16:15.269461Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#function to load the saved model\ndef loading_joblibPickle(vectorizer_name, model_name):\n    fpath = \"../input/starratingprediction-part-2/models/\"\n    vectorizer = joblib.load(fpath+vectorizer_name+\".sav\")\n    model = joblib.load(fpath+model_name+\".sav\")\n    return vectorizer, model","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:16:16.269664Z","iopub.execute_input":"2022-03-01T19:16:16.270465Z","iopub.status.idle":"2022-03-01T19:16:16.275521Z","shell.execute_reply.started":"2022-03-01T19:16:16.270427Z","shell.execute_reply":"2022-03-01T19:16:16.274519Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"#  **1. (Unigram, 75)**","metadata":{}},{"cell_type":"code","source":"vectorizer, model = loading_joblibPickle(\"vectorizer_uni75\", \"model_uni75\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:16:18.026750Z","iopub.execute_input":"2022-03-01T19:16:18.027198Z","iopub.status.idle":"2022-03-01T19:16:18.186303Z","shell.execute_reply.started":"2022-03-01T19:16:18.027167Z","shell.execute_reply":"2022-03-01T19:16:18.185435Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"> **generating the feature vector using learned vectorizer**","metadata":{}},{"cell_type":"code","source":"fvector = vectorizer.transform(X_test_df['Reviews']).toarray()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:16:20.047672Z","iopub.execute_input":"2022-03-01T19:16:20.047975Z","iopub.status.idle":"2022-03-01T19:16:39.776871Z","shell.execute_reply.started":"2022-03-01T19:16:20.047923Z","shell.execute_reply":"2022-03-01T19:16:39.775204Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"> **making predictions**","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(fvector)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:16:40.366075Z","iopub.execute_input":"2022-03-01T19:16:40.366740Z","iopub.status.idle":"2022-03-01T19:16:47.637324Z","shell.execute_reply.started":"2022-03-01T19:16:40.366683Z","shell.execute_reply":"2022-03-01T19:16:47.636573Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"> **Classification score**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:16:52.924858Z","iopub.execute_input":"2022-03-01T19:16:52.925492Z","iopub.status.idle":"2022-03-01T19:16:52.931873Z","shell.execute_reply.started":"2022-03-01T19:16:52.925456Z","shell.execute_reply":"2022-03-01T19:16:52.930936Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"target_names = ['1', '2', '3', '4', '5']\nclassification_score = classification_report(X_test_df['Rating'], y_pred, target_names=target_names)\nprint(classification_score)\nprint(\"Classfication Report for (Unigrams,75)\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:16:55.954919Z","iopub.execute_input":"2022-03-01T19:16:55.955480Z","iopub.status.idle":"2022-03-01T19:16:56.166387Z","shell.execute_reply.started":"2022-03-01T19:16:55.955437Z","shell.execute_reply":"2022-03-01T19:16:56.165525Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.60      0.84      0.70     21701\n           2       0.62      0.02      0.04      7417\n           3       0.40      0.10      0.16      9529\n           4       0.37      0.25      0.30     18412\n           5       0.76      0.89      0.82     67075\n\n    accuracy                           0.68    124134\n   macro avg       0.55      0.42      0.41    124134\nweighted avg       0.64      0.68      0.63    124134\n\nClassfication Report for (Unigrams,75)\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#  **2. (Unigram, 50)**","metadata":{}},{"cell_type":"code","source":"vectorizer, model=loading_joblibPickle(\"vectorizer_uni50\", \"model_uni50\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:17:00.699687Z","iopub.execute_input":"2022-03-01T19:17:00.699992Z","iopub.status.idle":"2022-03-01T19:17:00.814719Z","shell.execute_reply.started":"2022-03-01T19:17:00.699957Z","shell.execute_reply":"2022-03-01T19:17:00.813846Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"fvector = vectorizer.transform(X_test_df['Reviews']).toarray()\ny_pred = model.predict(fvector)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:17:03.336445Z","iopub.execute_input":"2022-03-01T19:17:03.336971Z","iopub.status.idle":"2022-03-01T19:17:20.850295Z","shell.execute_reply.started":"2022-03-01T19:17:03.336933Z","shell.execute_reply":"2022-03-01T19:17:20.849079Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"classification_score = classification_report(X_test_df['Rating'], y_pred, target_names=target_names)\nprint(classification_score)\nprint(\"Classfication Report for (Unigrams,50)\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:18:02.229627Z","iopub.execute_input":"2022-03-01T19:18:02.230509Z","iopub.status.idle":"2022-03-01T19:18:02.440786Z","shell.execute_reply.started":"2022-03-01T19:18:02.230458Z","shell.execute_reply":"2022-03-01T19:18:02.439748Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.56      0.86      0.68     21701\n           2       0.42      0.02      0.05      7417\n           3       0.27      0.13      0.18      9529\n           4       0.34      0.24      0.28     18412\n           5       0.78      0.85      0.82     67075\n\n    accuracy                           0.66    124134\n   macro avg       0.48      0.42      0.40    124134\nweighted avg       0.62      0.66      0.62    124134\n\nClassfication Report for (Unigrams,50)\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#  **3. (Bigram, 50)**","metadata":{}},{"cell_type":"code","source":"vectorizer, model=loading_joblibPickle(\"vectorizer_bi50\", \"model_bi50\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:18:04.196740Z","iopub.execute_input":"2022-03-01T19:18:04.197067Z","iopub.status.idle":"2022-03-01T19:18:05.025081Z","shell.execute_reply.started":"2022-03-01T19:18:04.197036Z","shell.execute_reply":"2022-03-01T19:18:05.024285Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"fvector = vectorizer.transform(X_test_df['Reviews']).toarray()\ny_pred = model.predict(fvector)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:18:06.629705Z","iopub.execute_input":"2022-03-01T19:18:06.630447Z","iopub.status.idle":"2022-03-01T19:18:59.166688Z","shell.execute_reply.started":"2022-03-01T19:18:06.630395Z","shell.execute_reply":"2022-03-01T19:18:59.165556Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"classification_score = classification_report(X_test_df['Rating'], y_pred, target_names=target_names)\nprint(classification_score)\nprint(\"Classfication Report for (Bigrams,50)\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:18:59.173676Z","iopub.execute_input":"2022-03-01T19:18:59.177125Z","iopub.status.idle":"2022-03-01T19:18:59.420605Z","shell.execute_reply.started":"2022-03-01T19:18:59.177054Z","shell.execute_reply":"2022-03-01T19:18:59.419974Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.68      0.76      0.72     21701\n           2       0.97      0.06      0.12      7417\n           3       0.85      0.10      0.17      9529\n           4       0.52      0.17      0.26     18412\n           5       0.71      0.97      0.82     67075\n\n    accuracy                           0.70    124134\n   macro avg       0.74      0.41      0.42    124134\nweighted avg       0.70      0.70      0.63    124134\n\nClassfication Report for (Bigrams,50)\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **4. (Unigram, 25)**","metadata":{}},{"cell_type":"code","source":"vectorizer, model=loading_joblibPickle(\"vectorizer_uni25\", \"model_uni25\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:19:02.278089Z","iopub.execute_input":"2022-03-01T19:19:02.278598Z","iopub.status.idle":"2022-03-01T19:19:02.350203Z","shell.execute_reply.started":"2022-03-01T19:19:02.278553Z","shell.execute_reply":"2022-03-01T19:19:02.349491Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"fvector = vectorizer.transform(X_test_df['Reviews']).toarray()\ny_pred = model.predict(fvector)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:19:04.236154Z","iopub.execute_input":"2022-03-01T19:19:04.236767Z","iopub.status.idle":"2022-03-01T19:19:14.130322Z","shell.execute_reply.started":"2022-03-01T19:19:04.236717Z","shell.execute_reply":"2022-03-01T19:19:14.129256Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"classification_score = classification_report(X_test_df['Rating'], y_pred, target_names=target_names)\nprint(classification_score)\nprint(\"Classfication Report for (Unigrams,25)\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:19:14.132223Z","iopub.execute_input":"2022-03-01T19:19:14.132748Z","iopub.status.idle":"2022-03-01T19:19:14.384034Z","shell.execute_reply.started":"2022-03-01T19:19:14.132698Z","shell.execute_reply":"2022-03-01T19:19:14.383127Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.50      0.87      0.63     21701\n           2       0.16      0.03      0.05      7417\n           3       0.20      0.19      0.19      9529\n           4       0.31      0.19      0.24     18412\n           5       0.81      0.77      0.79     67075\n\n    accuracy                           0.62    124134\n   macro avg       0.39      0.41      0.38    124134\nweighted avg       0.59      0.62      0.59    124134\n\nClassfication Report for (Unigrams,25)\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **5. (Bigram,25)**","metadata":{}},{"cell_type":"code","source":"vectorizer, model=loading_joblibPickle(\"vectorizer_bi25\", \"model_bi25\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:19:22.500442Z","iopub.execute_input":"2022-03-01T19:19:22.501145Z","iopub.status.idle":"2022-03-01T19:19:22.764680Z","shell.execute_reply.started":"2022-03-01T19:19:22.501103Z","shell.execute_reply":"2022-03-01T19:19:22.763748Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"fvector = vectorizer.transform(X_test_df['Reviews']).toarray()\ny_pred = model.predict(fvector)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:19:24.626701Z","iopub.execute_input":"2022-03-01T19:19:24.626982Z","iopub.status.idle":"2022-03-01T19:19:43.421295Z","shell.execute_reply.started":"2022-03-01T19:19:24.626953Z","shell.execute_reply":"2022-03-01T19:19:43.420307Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"classification_score = classification_report(X_test_df['Rating'], y_pred, target_names=target_names)\nprint(classification_score)\nprint(\"Classfication Report for (Bigrams,25)\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:19:43.423010Z","iopub.execute_input":"2022-03-01T19:19:43.425988Z","iopub.status.idle":"2022-03-01T19:19:43.673897Z","shell.execute_reply.started":"2022-03-01T19:19:43.425921Z","shell.execute_reply":"2022-03-01T19:19:43.672955Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.62      0.68      0.65     21701\n           2       0.81      0.03      0.05      7417\n           3       0.43      0.05      0.10      9529\n           4       0.35      0.16      0.22     18412\n           5       0.70      0.94      0.80     67075\n\n    accuracy                           0.66    124134\n   macro avg       0.58      0.37      0.36    124134\nweighted avg       0.62      0.66      0.59    124134\n\nClassfication Report for (Bigrams,25)\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **6. (Trigram,25)**","metadata":{}},{"cell_type":"code","source":"vectorizer, model = loading_joblibPickle(\"vectorizer_tri25\", \"model_tri25\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:19:51.907342Z","iopub.execute_input":"2022-03-01T19:19:51.907661Z","iopub.status.idle":"2022-03-01T19:19:52.207691Z","shell.execute_reply.started":"2022-03-01T19:19:51.907630Z","shell.execute_reply":"2022-03-01T19:19:52.206700Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"fvector = vectorizer.transform(X_test_df['Reviews'])\ny_pred = model.predict(fvector)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:19:54.555632Z","iopub.execute_input":"2022-03-01T19:19:54.555972Z","iopub.status.idle":"2022-03-01T19:19:58.788736Z","shell.execute_reply.started":"2022-03-01T19:19:54.555941Z","shell.execute_reply":"2022-03-01T19:19:58.787717Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"classification_score = classification_report(X_test_df['Rating'], y_pred, target_names=target_names)\nprint(classification_score)\nprint(\"Classfication Report for (Trigrams,25)\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T19:19:58.790242Z","iopub.execute_input":"2022-03-01T19:19:58.790500Z","iopub.status.idle":"2022-03-01T19:19:58.970345Z","shell.execute_reply.started":"2022-03-01T19:19:58.790470Z","shell.execute_reply":"2022-03-01T19:19:58.969286Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.70      0.18      0.28     21701\n           2       0.91      0.02      0.03      7417\n           3       0.66      0.02      0.04      9529\n           4       0.52      0.06      0.10     18412\n           5       0.57      0.99      0.72     67075\n\n    accuracy                           0.58    124134\n   macro avg       0.67      0.25      0.23    124134\nweighted avg       0.61      0.58      0.46    124134\n\nClassfication Report for (Trigrams,25)\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **<div style=\"text-align:center\">Performance of Multinomial Naive Bayes Classifier</div>**","metadata":{}},{"cell_type":"markdown","source":"<div>\n<div style=\"float:left\">\n<table style=\"border: 0.3px solid black\">\n  <tr>\n      <th style=\"text-align:center\" colspan=\"5\">Score of Trainig data</th>\n    </tr>\n    <tr style=\"border: 0.1px solid black\">\n    <th>(Ngram, Review Length(less than))</th>\n    <th>Accuracy</th>\n    <th>Precision</th>\n    <th>Recall</th>\n    <th>F1-Score</th>\n  </tr>\n    <tr>\n    <td>Unigram, 75</td>    \n    <td>0.76</td>\n    <td>0.76</td>\n    <td>0.76</td>\n    <td>0.70</td>\n  </tr>\n  <tr>\n    <td>Unigram, 50</td>   \n      <td>0.78</td>\n    <td>0.77</td>\n    <td>0.78</td>\n      <td>0.73</td>\n  </tr>\n  <tr>\n    <td>Bigram, 50</td> \n   <td>0.83</td>\n    <td>0.85</td>\n    <td>0.83</td>\n    <td>0.80</td>\n  </tr>\n  <tr>\n    <td>Unigram, 25</td>\n    <td>0.81</td>\n    <td>0.80</td>\n    <td>0.81</td>\n    <td>0.76</td>\n  </tr>\n  <tr>\n    <td>Bigram, 25</td>\n    <td>0.83</td>\n    <td>0.84</td>\n    <td>0.83</td>\n    <td>0.79</td>\n  </tr>\n  <tr>\n    <td>Trigram, 25</td> \n    <td>0.78</td>\n    <td>0.83</td>\n    <td>0.78</td>\n    <td>0.73</td>\n  </tr>\n</table>\n    </div>\n    \n    \n    \n <div style=\"float:right\">\n<table style=\"border: 0.3px solid black\">\n     <tr>\n      <th style=\"text-align:center\" colspan=\"5\">Score of Test data</th>\n    </tr>\n  <tr style=\"border: 0.1px solid black\">\n    <th>(Ngram, Review Length(less than))</th>\n    <th>Accuracy</th>\n    <th>Precision</th>\n    <th>Recall</th>\n    <th>F1-Score</th>\n  </tr>\n    <tr>\n    <td>Unigram, 75</td>    \n    <td>0.68</td>\n    <td>0.64</td>\n    <td>0.68</td>\n    <td>0.63</td>\n    </tr>\n  <tr>\n    <td>Unigram, 50</td>   \n    <td>0.66</td>\n    <td>0.62</td>\n    <td>0.66</td>\n    <td>0.62</td>\n  </tr>\n  <tr>\n    <td>Bigram, 50</td> \n    <td>0.70</td>\n    <td>0.70</td>\n    <td>0.70</td>\n    <td>0.63</td>\n  </tr>\n    <tr>\n    <td>Unigram, 25</td>\n    <td>0.62</td>\n    <td>0.59</td>\n    <td>0.62</td>\n    <td>0.59</td>\n  </tr>\n  <tr>\n    <td>Bigram, 25</td>\n    <td>0.66</td>\n    <td>0.62</td>\n    <td>0.66</td>\n    <td>0.59</td>\n  </tr>\n  <tr>\n    <td>Trigram, 25</td> \n    <td>0.58</td>\n    <td>0.61</td>\n    <td>0.58</td>\n    <td>0.46</td>\n  </tr>\n</table>\n          </div>\n    </div>","metadata":{}},{"cell_type":"markdown","source":"# Bigrams are found to be the best amongst all and unigrams are doing good than trigram as well.\n\n# We will be tackling the class imbalance to improve the performance of our classifiers as we can see in the below image how skewed our dataset is!","metadata":{}},{"cell_type":"markdown","source":"![image.png](attachment:49745d2c-fcd4-40aa-b57e-dda5015a8593.png)\n\nSource of image: <a href=\"https://www.kaggle.com/rajatagg/star-rating-prediction-part-2?scriptVersionId=88922233\">Part-1: Data Preprocessing</a>","metadata":{},"attachments":{"49745d2c-fcd4-40aa-b57e-dda5015a8593.png":{"image/png":"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"}}}]}